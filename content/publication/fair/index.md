+++
title = "FAIR : Frugal ADAS for Indian Roads"
date = 2020-05-02T00:00:00

# Authors. Comma separated list, e.g. `["Bob Smith", "David Jones"]`.
authors = ["Vineetha Kondameedi", "Santosh Shet", "Akshaj Verma", "admin", "Prashant Kumar", "Chiranjib Bhattacharyya", "Soma Biswas"]

# Publication type.
# Legend:
# 0 = Uncategorized
# 1 = Conference paper
# 2 = Journal article
# 3 = Manuscript
# 4 = Report
# 5 = Book
# 6 = Book section
publication_types = ["3"]

# Publication name and optional abbreviated version.
publication = "Preprint"
publication_short = ""

# Abstract.
abstract = "Frugal ADAS for Indian Roads (FAIR) is an intelligent system designed as a plug-and-play software which can be integrated with any vehicle. FAIR was designed specifically for Indian roads, which have a different dynamic (animal presence, behaviour of pedestrians, high density of objects on road) as compared to European and American roads, to perform object detection with a competitively high accuracy while keeping development costs low. For testing, we collect our dataset on Indian roads (near IISc Bangalore) with webcam with objects in varying illumination and distances from the camera. We demonstrate that FAIR performs object detection, for 15 classes, exceedingly well in well-light conditions where average pixel value lies between 56%-62% (8AM to 6PM), object distance from the car lies between 0-30m, and the vehicle speed is in the range of 0-40km/h. FAIR can be augmented to use mobile cameras and can offer a great night time performance. It also has the potential to further support downstream tasks such as collision avoidance, blind spot information and speed breaker/pothole detections. With a competitive accuracy, high inference rate, ability to work in low-illumination settings, and low memory-footprint to run on the portable NVIDIA TX2 board, we conclude that FAIR is an ADAS system can be introduced in the Indian markets at a cost of Rs. 30,000 (or about 400 USD)."

# Summary. An optional shortened abstract.
summary = ""

# Digital Object Identifier (DOI)
# doi = "10.1038/s41598-020-61289-4"

# Is this a featured publication? (true/false)
featured = false

# Tags (optional).
#   Set `tags = []` for no tags, or use the form `tags = ["A Tag", "Another Tag"]` for one or more tags.
tags = ["Deep Learning", "Computer Vision", "ADAS", "Detection", "Segmentation", "Tata"]

# Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["deep-learning"]` references
#   `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
# projects = []

# Slides (optional).
#   Associate this publication with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references
#   `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
# slides = "example-slides"

# Links (optional).
url_pdf = ""
url_preprint = "FAIR_ADAS.pdf"
url_code = ""
url_dataset = ""
url_project = ""
url_slides = ""
url_video = ""
url_poster = ""
url_source = ""

# Custom links (optional).
# For multiple links, use the form `[{...}, {...}, {...}]`.
# links = [{name = "Supplementary Material", url = "https://static-content.springer.com/esm/art%3A10.1038%2Fs41598-020-61289-4/MediaObjects/41598_2020_61289_MOESM1_ESM.pdf"},
#{name = "Poster (earlier version)", url = "PosterA0.pdf"}]

# Does this page contain LaTeX math? (true/false)
math = false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
[image]
  # Caption (optional)
  # caption = "Image credit: **Juan David Leong√≥mez 2020**"

  # Focal point (optional)
  # Options: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight
  focal_point = "BottomLeft"

+++

For more information on this project, or to get access to code and datasets used in this project, please get in touch with me or one of the authors.